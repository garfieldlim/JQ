{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cf47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, Partition, utility\n",
    "from pymilvus import Milvus, DataType, Collection, MilvusException\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import fasttext\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7856f",
   "metadata": {},
   "source": [
    "Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fdf9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ca411",
   "metadata": {},
   "source": [
    "Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53183d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_list = [\n",
    "    'text_collection',\n",
    "    'author_collection',\n",
    "    'title_collection',\n",
    "    'contact_collection',\n",
    "    'name_collection',\n",
    "    'position_collection',\n",
    "    'department_collection',\n",
    "    'date_collection',\n",
    "]\n",
    "fields_list = [\n",
    "    'text',\n",
    "    'author',\n",
    "    'title',\n",
    "    'contact',\n",
    "    'name',\n",
    "    'position',\n",
    "    'department',\n",
    "    'date',\n",
    "]\n",
    "collections_dict = {\n",
    "    \"text_collection\": [\"uuid\", \"text_id\", \"text\", \"embeds\", \"media\", \"link\", \"partition_name\"],\n",
    "    \"author_collection\": [\"uuid\", \"author\", \"embeds\", \"partition_name\"],\n",
    "    \"title_collection\": [\"uuid\", \"title\", \"embeds\", \"partition_name\"],\n",
    "    \"date_collection\": [\"uuid\", \"date\", \"embeds\", \"partition_name\"],\n",
    "    \"contact_collection\": [\"uuid\", \"contact\", \"embeds\", \"partition_name\"],\n",
    "    \"department_collection\": [\"uuid\", \"department\", \"embeds\", \"partition_name\"],\n",
    "    \"name_collection\": [\"uuid\", \"name\", \"embeds\", \"partition_name\"],\n",
    "    \"position_collection\": [\"uuid\", \"position\", \"embeds\", \"partition_name\"]\n",
    "}\n",
    "\n",
    "partitions = {\n",
    "    \"documents_partition\": [\"text_collection\", \"author_collection\", \"title_collection\", \"date_collection\"],\n",
    "    \"social_posts_partition\": [\"text_collection\", \"date_collection\"],\n",
    "    \"contacts_partition\": [\"name_collection\", \"text_collection\", \"contact_collection\", \"department_collection\"],\n",
    "    \"people_partition\": [\"text_collection\",\"name_collection\",\"position_collection\",\"department_collection\"],\n",
    "    \"usjr_documents_partition\": [\"text_collection\", \"title_collection\"],\n",
    "    \"scs_documents_partition\" : [\"text_collection\"],\n",
    "    \"religious_admin_people_partition\": [\"text_collection\",\"name_collection\",\"position_collection\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63021bbb",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e14b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the connection already exists\n",
    "if connections.has_connection('default'):\n",
    "    connections.remove_connection('default')  # Disconnect if it exists\n",
    "\n",
    "# Now, reconnect with your new configuration\n",
    "connections.connect(alias='default', host='localhost', port='19530')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa94f8",
   "metadata": {},
   "source": [
    "Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fefa54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = fasttext.load_model(\"C:/Users/Jillian/Desktop/crawl-300d-2M-subword.bin\")\n",
    "def get_embedding(text, embedding_type):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    model = \"text-embedding-ada-002\"\n",
    "    if embedding_type == 'openai':\n",
    "        return openai.Embedding.create(input=[text.lower()], model=model)['data'][0]['embedding']\n",
    "    elif embedding_type == 'fasttext':\n",
    "        return fasttext_model.get_sentence_vector(text.lower())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding_type. Expected 'openai' or 'fasttext'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde8963",
   "metadata": {},
   "source": [
    "Symbol remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83715d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphanumeric(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbcf0d",
   "metadata": {},
   "source": [
    "Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff960efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_query(query):\n",
    "    return {'question1536': get_embedding(query.lower(), 'openai'),'question300': get_embedding(query.lower(), 'fasttext').tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a584312",
   "metadata": {},
   "source": [
    "Search collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4fa838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_collections(vectors, partition_names):\n",
    "    question1536=vectors['question1536']\n",
    "    question300=vectors['question300']\n",
    "    results_dict = {}\n",
    "    search_params = {\n",
    "    \"metric_type\": \"L2\",  # Distance metric, can be L2, IP (Inner Product), etc.\n",
    "    \"offset\": 0,}\n",
    "    for name in fields_list:\n",
    "        try:\n",
    "            if name == 'text':\n",
    "                collection = Collection(f\"{name}_collection\")\n",
    "                collection.load()\n",
    "                result = collection.search(\n",
    "                    data=[question1536],\n",
    "                    anns_field=\"embeds\",\n",
    "                    param=search_params,\n",
    "                    limit=10,\n",
    "                    partition_names=partition_names,\n",
    "                    output_fields=['uuid', 'text_id'],\n",
    "                    consistency_level=\"Strong\"\n",
    "                )\n",
    "                results_dict[name] = result\n",
    "            else:\n",
    "                collection = Collection(f\"{name}_collection\")\n",
    "                collection.load()\n",
    "                result = collection.search(\n",
    "                    data=[question300],\n",
    "                    anns_field=\"embeds\",\n",
    "                    param=search_params,\n",
    "                    limit=10,\n",
    "                    partition_names=partition_names,\n",
    "                    output_fields=['uuid'],\n",
    "                    consistency_level=\"Strong\"\n",
    "                )\n",
    "                results_dict[name] = result\n",
    "        except MilvusException as e:\n",
    "            if 'partition name' in str(e) and 'not found' in str(e):\n",
    "                print(f\"Partition '{partition_names}' not found in collection '{name}', skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                raise e  # if it's a different kind of MilvusException, we still want to raise it\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c6bfe",
   "metadata": {},
   "source": [
    "Check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f830cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_collection_dimension(collection):\n",
    "    collection_params = collection.schema\n",
    "    vector_field = [field for field in collection_params.fields if field.dtype == DataType.FLOAT_VECTOR][0]\n",
    "    print(f\"Dimension of vectors in collection '{collection.name}': {vector_field.params['dim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d53de",
   "metadata": {},
   "source": [
    "Process results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2d24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results_dict):\n",
    "    json_results = {}\n",
    "\n",
    "    for collection_name, result in results_dict.items():\n",
    "        for query_hits in result:\n",
    "            for hit in query_hits:\n",
    "                if collection_name == 'text':\n",
    "                    id_field = 'entity_id'\n",
    "                    id_value = hit.entity.get('text_id')\n",
    "                else:\n",
    "                    id_field = 'entity_id'\n",
    "                    id_value = hit.id\n",
    "                \n",
    "                # Create the result dictionary\n",
    "                result_dict = {\n",
    "                    id_field: id_value,\n",
    "                    \"distance\": hit.distance,\n",
    "                    \"collection\": collection_name\n",
    "                }\n",
    "\n",
    "                # If the id_value is already in the results and the new distance is greater, skip\n",
    "                if id_value in json_results and json_results[id_value][\"distance\"] < hit.distance:\n",
    "                    continue\n",
    "\n",
    "                # Otherwise, update/insert the result\n",
    "                json_results[id_value] = result_dict\n",
    "                \n",
    "            json_results_list = list(json_results.values())\n",
    "            json_results_sorted = sorted(json_results_list, key=lambda x: x['distance'])\n",
    "    \n",
    "    return json_results_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02567d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_results(json_results_sorted, partition_names):\n",
    "    # Load all collections beforehand\n",
    "    collections = {name: Collection(f\"{name}_collection\") for name in fields_list}\n",
    "\n",
    "    # Create a list of entity IDs for the query\n",
    "    entity_ids = [result[\"entity_id\"] for result in json_results_sorted]\n",
    "\n",
    "    # Preparing an empty dictionary for each field in the results\n",
    "    for result in json_results_sorted:\n",
    "        for name in fields_list:\n",
    "            result[name] = []\n",
    "\n",
    "    # Query for all relevant records at once\n",
    "    for name, collection in collections.items():\n",
    "        try:\n",
    "            # Prepare the query\n",
    "            output_fields = []\n",
    "            if name == 'text':\n",
    "                query_field = \"text_id\"\n",
    "                output_fields = [name, 'text_id']\n",
    "            else:\n",
    "                query_field = \"uuid\"\n",
    "                output_fields = [name]\n",
    "\n",
    "            query = f\"{query_field} in {entity_ids}\"\n",
    "\n",
    "            query_results = collection.query(\n",
    "                expr=query, \n",
    "                offset=0, \n",
    "                limit=len(entity_ids), \n",
    "                partition_names=[partition_names], \n",
    "                output_fields=output_fields, \n",
    "                consistency_level=\"Strong\"\n",
    "            )\n",
    "\n",
    "            # Append the results to the relevant fields in the results dictionary\n",
    "            for query_result in query_results:\n",
    "                for result in json_results_sorted:\n",
    "                    if (name == 'text' and result[\"entity_id\"] == query_result[\"text_id\"]) or (name != 'text' and result[\"entity_id\"] == query_result[\"uuid\"]):\n",
    "                        result[name].append(query_result[name])\n",
    "            final_results = []\n",
    "            for result in json_results_sorted:\n",
    "                obj = {}\n",
    "                for item in result:\n",
    "                    # If item is not 'entity_id' or 'distance' and the item's value is not empty\n",
    "                    if item not in ['entity_id', 'collection'] and result[item]:\n",
    "                        obj[item] = result[item]\n",
    "                final_results.append(obj)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with collection {name}: {str(e)}\")\n",
    "    return final_results[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4f87e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, string_json):\n",
    "    # Format the input as per the desired conversation format\n",
    "    conversation = [\n",
    "        {'role': 'system', 'content': \"\"\"You are Josenian Quiri. University of San Jose- Recoletos' general knowledge base assistant. Refer to yourself as JQ. If there are links, give the link as well.\"\"\"},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "        {'role': 'system', 'content': f'Here is the database JSON from your knowledge base (note: select only the correct answer): \\n{string_json[:4500]}'},\n",
    "        {'role': 'user', 'content': ''}\n",
    "    ]\n",
    "    \n",
    "    # Convert the conversation to a string\n",
    "    conversation_str = ''.join([f'{item[\"role\"]}: {item[\"content\"]}\\n' for item in conversation])\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=conversation,\n",
    "      temperature=1,\n",
    "      max_tokens=1000,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    # Extract the generated response from the API's response\n",
    "    generated_text = response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "    # Return the response\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84d78bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18388\\2040629935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf_attribute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier_model/clf_attribute.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf_partition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier_model/clf_partition.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# load encoders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mle_attribute\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'classifier_model/le_attribute.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32mC:\\anaconda\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "clf_attribute = joblib.load('classifier_model/clf_attribute.pkl')\n",
    "clf_partition = joblib.load('classifier_model/clf_partition.pkl')\n",
    "\n",
    "# load encoders\n",
    "le_attribute = joblib.load('classifier_model/le_attribute.pkl')\n",
    "le_partition = joblib.load('classifier_model/le_partition.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a35b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_attribute = joblib.load('classifier_model/clf_attribute.pkl')\n",
    "clf_partition = joblib.load('classifier_model/clf_partition.pkl')\n",
    "\n",
    "# load encoders\n",
    "le_attribute = joblib.load('classifier_model/le_attribute.pkl')\n",
    "le_partition = joblib.load('classifier_model/le_partition.pkl')\n",
    "\n",
    "def predict_attribute(embeds):\n",
    "    # transform input to the right format\n",
    "    X = np.stack([embeds])\n",
    "\n",
    "    # predict probabilities across all possible labels\n",
    "    probas = clf_attribute.predict_proba(X)[0]\n",
    "\n",
    "    # get class labels in descending order of probability\n",
    "    classes = clf_attribute.classes_\n",
    "    ranked_classes = [x for _, x in sorted(zip(probas, classes), reverse=True)]\n",
    "\n",
    "    # return the names instead of the encoded labels\n",
    "    return le_attribute.inverse_transform(ranked_classes)\n",
    "\n",
    "def predict_partition(embeds):\n",
    "    # transform input to the right format\n",
    "    X = np.stack([embeds])\n",
    "\n",
    "    # predict probabilities across all possible labels\n",
    "    probas = clf_partition.predict_proba(X)[0]\n",
    "\n",
    "    # get class labels in descending order of probability\n",
    "    classes = clf_partition.classes_\n",
    "    ranked_classes = [x for _, x in sorted(zip(probas, classes), reverse=True)]\n",
    "\n",
    "    # return the names instead of the encoded labels\n",
    "    return le_partition.inverse_transform(ranked_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_partitions(vectors):\n",
    "    return ['social_posts_partition', 'documents_partition', 'people_partition', \"contacts_partition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd95a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer():\n",
    "    while True:\n",
    "        try:\n",
    "            prompt = input(\"You: \")\n",
    "            if not prompt:\n",
    "                print(\"No input provided. Try again.\")\n",
    "                continue\n",
    "            vectors = vectorize_query(prompt)\n",
    "            if vectors is None:\n",
    "                print(\"No vectors returned. Check your vectorize_query function.\")\n",
    "                continue\n",
    "            ranked_partitions = predict_partition(vectors['question300'])\n",
    "            if ranked_partitions is None:\n",
    "                print(\"No ranked_partitions returned. Check your ranking_partitions function.\")\n",
    "                continue\n",
    "            partition = 0\n",
    "            correct = 0\n",
    "            display(ranked_partitions)\n",
    "            display(ranked_partitions[partition])\n",
    "            while correct != 1:\n",
    "                results_dict = search_collections(vectors, [ranked_partitions[partition]])\n",
    "                if results_dict is None:\n",
    "                    print(\"No results returned. Check your search_collections function.\")\n",
    "                    break\n",
    "                json_results_sorted = process_results(results_dict)\n",
    "                if json_results_sorted is None:\n",
    "                    print(\"No sorted results returned. Check your process_results function.\")\n",
    "                    break\n",
    "                final_results = populate_results(json_results_sorted, ranked_partitions[partition])\n",
    "                if final_results is None:\n",
    "                    print(\"No final results returned. Check your populate_results function.\")\n",
    "                    break\n",
    "                string_json = json.dumps(final_results)\n",
    "                display(string_json)\n",
    "                generated_text = generate_response(prompt, string_json)\n",
    "                if generated_text is None:\n",
    "                    print(\"No response generated. Check your generate_response function.\")\n",
    "                    break\n",
    "                print(f\"JQ: {generated_text}\")\n",
    "                correct = input(\"Is the answer correct? 1-Y, 0-N: \")\n",
    "                if correct not in ['0', '1']:\n",
    "                    print(\"Invalid input. Try again.\")\n",
    "                elif partition <= 3 :\n",
    "                    partition = partition + 1\n",
    "                else:\n",
    "                    partition = 0\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00558ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7d616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc6ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285947f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75220d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
