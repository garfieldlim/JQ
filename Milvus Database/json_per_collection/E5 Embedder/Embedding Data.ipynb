{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d535edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "folder_path = \"documents\"  # Replace this with the actual path to your folder\n",
    "\n",
    "def load_json_files_into_dictionary(folder_path):\n",
    "    data_dict = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            key = os.path.splitext(filename)[0]  # Exclude the \".json\" extension from the filename\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    data_dict[key] = data\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error: Failed to load JSON from file '{filename}'. Skipping this file.\")\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cc7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_dict = load_json_files_into_dictionary(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6713371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = ['title','text','author','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5524995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in json_data_dict:\n",
    "    json_data_dict[name] = [item for item in json_data_dict[name] if not(any(fname in item and (item[fname] == ' ' or item[fname] == '') for fname in field_names))]\n",
    "    for item in json_data_dict[name]:\n",
    "        if 'embeds' in item:\n",
    "            del item['embeds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae93a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_collection {'link': 'https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/25', 'media': ' ', 'partition_name': 'documents_partition', 'text': 'Responding to the challenges of global employment, universities recognize the need to produce graduates who meet the ever-changing demands of work and life in the national and global environment. This paper investigates the extent of practice of graduate attributes among graduating college students of a Catholic University. It determines the influence of graduate attributes in studentsâ€™ lives. Using a sequential explanatory mixed-method design, the findings revealed that the participants developed the graduate attributes to a high extent. Remarkable implication signifies that university education has successfully prepared and trained students to meet the challenges of national and global employment and industry. link: https://rmrj.usjr.edu.ph/rmrj/index.php/RMRJ/article/view/25', 'text_id': '0105944d-3ebe-45f0-89f8-53e07f2d345d', 'uuid': '1b03036e-fe43-4ab1-9e07-7848e38bb79e'}\n",
      "\n",
      "\n",
      "title_collection {'uuid': '111553fe-23fc-45e4-ad46-0c56b61aee0e', 'title': 'Timeless Existence and Principle of Creation: Notions Embedded in John 1:1, \"In the Beginning Was the Word\"', 'partition_name': 'documents_partition'}\n",
      "\n",
      "\n",
      "author_collection {'uuid': '111553fe-23fc-45e4-ad46-0c56b61aee0e', 'author': 'Emiliano C. De Catalina', 'partition_name': 'documents_partition'}\n",
      "\n",
      "\n",
      "date_collection {'uuid': '111553fe-23fc-45e4-ad46-0c56b61aee0e', 'date': '2022-05-25 May 25 2022', 'partition_name': 'documents_partition'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in json_data_dict:\n",
    "    print(name, json_data_dict[name][0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1851283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "for name in json_data_dict:\n",
    "    for item in json_data_dict[name]:\n",
    "        embeds = []\n",
    "        for field in item:\n",
    "            if field not in ['uuid', 'partition_name', 'text_id']:\n",
    "                embeds.append(f\"{field} is {item[field]}\")\n",
    "        item['embeds'] = ', '.join(embeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f635f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def embed_string(text: str):\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "    model = AutoModel.from_pretrained('intfloat/e5-large-v2')\n",
    "\n",
    "    # Prefix the text with 'query: '\n",
    "    text = 'query: ' + text\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Generate model outputs\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Average pool the last hidden states and apply the attention mask\n",
    "    embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "\n",
    "    # Normalize the embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "    # Convert tensor to list\n",
    "    embeddings_list = embeddings.tolist()\n",
    "\n",
    "    return embeddings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████▏                                | 43/196 [01:38<05:42,  2.24s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for name in json_data_dict:\n",
    "    for item in tqdm(json_data_dict[name]):\n",
    "        item['embeds'] = embed_string(item['embeds'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95422ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in json_data_dict:\n",
    "# #     print(name, json_data_dict[name][0]['embeds'])\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in json_data_dict:\n",
    "    for item in json_data_dict[name]:\n",
    "        item['embeds'] = item['embeds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_save_json_files(folder_path):\n",
    "    for name in json_data_dict:\n",
    "        file_path = os.path.join(folder_path, f\"{name}.json\")\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(json_data_dict[name], file)\n",
    "\n",
    "# Call the function to update and save the JSON files\n",
    "update_and_save_json_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da3018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7703d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cab0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
