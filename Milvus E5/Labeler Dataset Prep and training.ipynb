{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dad137",
   "metadata": {},
   "source": [
    "Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a0c83a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition_name\n",
      "social_posts_partition    189\n",
      "documents_partition       189\n",
      "people_partition           43\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>partition_name</th>\n",
       "      <th>embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>announcement is read | rev. fr. hernando coja,...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.014242676086723804, -0.05774782598018646, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announcement is join the recollect community a...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.009649019688367844, -0.0820484608411789, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announcement is #usjradvisory | all classes ar...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.021807659417390823, -0.07729943096637726, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>announcement is read | this is the second time...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.005872523412108421, -0.09072086960077286, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>announcement is ?????????????????????? ???? ??...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.03550581634044647, -0.06325256079435349, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>jennifer d. paã±o, jeralden r. jumao-as, march...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>randy e. pederi mary gretchen f. chaves</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>teovy erdel bongcales, ariel balunan, loriemar...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>steven elizalde, romeo patan mary gretchen chaves</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>albie mae g. sumaylo, christine mae s. babon, ...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                values  \\\n",
       "0    announcement is read | rev. fr. hernando coja,...   \n",
       "1    announcement is join the recollect community a...   \n",
       "2    announcement is #usjradvisory | all classes ar...   \n",
       "3    announcement is read | this is the second time...   \n",
       "4    announcement is ?????????????????????? ???? ??...   \n",
       "..                                                 ...   \n",
       "416  jennifer d. paã±o, jeralden r. jumao-as, march...   \n",
       "417            randy e. pederi mary gretchen f. chaves   \n",
       "418  teovy erdel bongcales, ariel balunan, loriemar...   \n",
       "419  steven elizalde, romeo patan mary gretchen chaves   \n",
       "420  albie mae g. sumaylo, christine mae s. babon, ...   \n",
       "\n",
       "             partition_name                                             embeds  \n",
       "0    social_posts_partition  [0.014242676086723804, -0.05774782598018646, 0...  \n",
       "1    social_posts_partition  [0.009649019688367844, -0.0820484608411789, 0....  \n",
       "2    social_posts_partition  [0.021807659417390823, -0.07729943096637726, 0...  \n",
       "3    social_posts_partition  [0.005872523412108421, -0.09072086960077286, 0...  \n",
       "4    social_posts_partition  [0.03550581634044647, -0.06325256079435349, 0....  \n",
       "..                      ...                                                ...  \n",
       "416     documents_partition                                               None  \n",
       "417     documents_partition                                               None  \n",
       "418     documents_partition                                               None  \n",
       "419     documents_partition                                               None  \n",
       "420     documents_partition                                               None  \n",
       "\n",
       "[421 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# List of directories\n",
    "directories = ['social_posts', 'documents', 'people']\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# For each directory\n",
    "for directory in directories:\n",
    "    # Specify the directory containing the JSON files\n",
    "    folder_path = os.path.join(directory)\n",
    "\n",
    "    # Get a list of all JSON files in the directory\n",
    "    json_files = [pos_json for pos_json in os.listdir(folder_path) if pos_json.endswith('.json')]\n",
    "\n",
    "    # For each JSON file\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(folder_path, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "\n",
    "            # Remove the 'embeds' attribute\n",
    "            if 'embeds' in json_text:\n",
    "                del json_text['embeds']\n",
    "\n",
    "            # Convert JSON to dataframe\n",
    "            # Note: as of pandas 1.0.0, json_normalize has been moved to pandas.json_normalize\n",
    "            json_df = pd.json_normalize(json_text)\n",
    "\n",
    "            # Concatenate the dataframes\n",
    "            df = pd.concat([df, json_df], ignore_index=True)\n",
    "# Drop 'uuid' and 'text_id' columns in-place\n",
    "df.drop(['uuid', 'text_id', 'link','media', 'date',], axis=1, inplace=True)\n",
    "\n",
    "# Function to combine columns\n",
    "def combine_columns(row):\n",
    "    row = row.drop(['partition_name', 'embeds'])\n",
    "    values = ', '.join(row.dropna().astype(str).values)\n",
    "    return values\n",
    "\n",
    "# Apply the function to each row\n",
    "df['values'] = df.apply(combine_columns, axis=1)\n",
    "\n",
    "# Convert 'values' to lowercase\n",
    "df['values'] = df['values'].str.lower()\n",
    "\n",
    "# Create new dataframe with required columns\n",
    "df_new = df[['values', 'partition_name', 'embeds']]\n",
    "\n",
    "# Exclude rows where 'values' is empty\n",
    "df_new = df_new[df_new['values'] != \"\"]\n",
    "\n",
    "\n",
    "df = df_new\n",
    "\n",
    "partition_counts = df['partition_name'].value_counts()\n",
    "\n",
    "def split_into_parts(row):\n",
    "    text = row['values']\n",
    "    tokens = text.split()\n",
    "    length = len(tokens)\n",
    "    if length > 300:\n",
    "        parts = [\n",
    "            ' '.join(tokens[:length//6]),\n",
    "            ' '.join(tokens[length//6:(2*length)//6]),\n",
    "            ' '.join(tokens[(2*length)//6:(3*length)//6]),\n",
    "            ' '.join(tokens[(3*length)//6:(4*length)//6]),\n",
    "            ' '.join(tokens[(4*length)//6:(5*length)//6]),\n",
    "            ' '.join(tokens[(5*length)//6:])\n",
    "        ]\n",
    "    elif length >= 200:\n",
    "        parts = [\n",
    "            ' '.join(tokens[:length//4]),\n",
    "            ' '.join(tokens[length//4:length//2]),\n",
    "            ' '.join(tokens[length//2:(3*length)//4]),\n",
    "            ' '.join(tokens[(3*length)//4:])\n",
    "        ]\n",
    "    elif length >= 90:\n",
    "        parts = [\n",
    "            ' '.join(tokens[:length//3]),\n",
    "            ' '.join(tokens[length//3:(2*length)//3]),\n",
    "            ' '.join(tokens[(2*length)//3:])\n",
    "        ]\n",
    "    else:\n",
    "        parts = text\n",
    "    return parts\n",
    "\n",
    "# Create a temporary DataFrame for rows with 'social_posts_partition' or 'people_partition'\n",
    "temp_df = df[df['partition_name'].isin(['social_posts_partition', 'people_partition'])].copy()\n",
    "\n",
    "# Apply the function to split 'values' into parts\n",
    "temp_df['values'] = temp_df.apply(split_into_parts, axis=1)\n",
    "\n",
    "# Explode the 'values' into separate rows\n",
    "temp_df = temp_df.explode('values')\n",
    "\n",
    "# Exclude rows with 'social_posts_partition' or 'people_partition' from original DataFrame\n",
    "df = df[~df['partition_name'].isin(['social_posts_partition', 'people_partition'])]\n",
    "\n",
    "# Concatenate the original DataFrame with the temporary DataFrame\n",
    "df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# Print the result\n",
    "from math import ceil\n",
    "\n",
    "# Get rows with 'documents_partition'\n",
    "documents_partition_df = df[df['partition_name'] == 'documents_partition'].copy()\n",
    "\n",
    "# Determine the number of rows per segment\n",
    "# Determine the number of segments\n",
    "num_segments = 189\n",
    "\n",
    "# Determine the number of rows per segment\n",
    "rows_per_segment = len(documents_partition_df) // num_segments\n",
    "\n",
    "# If there are extra rows, add them to the last segment\n",
    "extra_rows = len(documents_partition_df) % num_segments\n",
    "\n",
    "segments = []\n",
    "for i in range(num_segments):\n",
    "    start_idx = i * rows_per_segment\n",
    "    end_idx = (i + 1) * rows_per_segment if i != num_segments - 1 else (i + 1) * rows_per_segment + extra_rows\n",
    "    segment = ' '.join(documents_partition_df['values'].iloc[start_idx:end_idx])\n",
    "    segments.append(segment)\n",
    "\n",
    "# Create a new DataFrame with the segments\n",
    "new_documents_partition_df = pd.DataFrame({\n",
    "    'values': segments,\n",
    "    'partition_name': ['documents_partition'] * num_segments,\n",
    "    'embeds': [None] * num_segments # You may want to handle 'embeds' differently\n",
    "})\n",
    "\n",
    "# Exclude rows with 'documents_partition' from original DataFrame\n",
    "df = df[df['partition_name'] != 'documents_partition']\n",
    "\n",
    "# Concatenate the original DataFrame with the new DataFrame\n",
    "df = pd.concat([df, new_documents_partition_df], ignore_index=True)\n",
    "\n",
    "# Print the result\n",
    "partition_counts = df['partition_name'].value_counts()\n",
    "print(partition_counts)\n",
    "df.loc[df['partition_name'] == 'social_posts_partition', 'values'] = 'announcement is ' + df['values'].astype(str)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e453af8",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d1bc6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "transformer_model = AutoModel.from_pretrained('intfloat/e5-large-v2')\n",
    "\n",
    "def string_to_embedding(text: str):\n",
    "#     tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "#     transformer_model = AutoModel.from_pretrained('intfloat/e5-large-v2') # Renamed variable here\n",
    "    text = 'query: ' + text\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = transformer_model(**inputs) # Updated variable here\n",
    "    embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    embeddings_list = embeddings.tolist()\n",
    "    return embeddings_list[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9cf51cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding values: 100%|███████████████████████| 421/421 [01:35<00:00,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Embedding values\")\n",
    "df['embeds'] = df['values'].progress_apply(string_to_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "19e1b9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>partition_name</th>\n",
       "      <th>embeds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>announcement is read | rev. fr. hernando coja,...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.018143652006983757, -0.04928550496697426, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announcement is join the recollect community a...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.01835092157125473, -0.0741904154419899, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announcement is #usjradvisory | all classes ar...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.03154794126749039, -0.06222093477845192, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>announcement is read | this is the second time...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.015062374994158745, -0.07406798750162125, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>announcement is ?????????????????????? ???? ??...</td>\n",
       "      <td>social_posts_partition</td>\n",
       "      <td>[0.034660838544368744, -0.058060452342033386, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>jennifer d. paã±o, jeralden r. jumao-as, march...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>[-0.007246498018503189, -0.04587141051888466, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>randy e. pederi mary gretchen f. chaves</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>[-0.004172301385551691, -0.047382697463035583,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>teovy erdel bongcales, ariel balunan, loriemar...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>[-0.01086932048201561, -0.04749814048409462, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>steven elizalde, romeo patan mary gretchen chaves</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>[0.00848416518419981, -0.025945544242858887, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>albie mae g. sumaylo, christine mae s. babon, ...</td>\n",
       "      <td>documents_partition</td>\n",
       "      <td>[-0.001516345189884305, -0.051354434341192245,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                values  \\\n",
       "0    announcement is read | rev. fr. hernando coja,...   \n",
       "1    announcement is join the recollect community a...   \n",
       "2    announcement is #usjradvisory | all classes ar...   \n",
       "3    announcement is read | this is the second time...   \n",
       "4    announcement is ?????????????????????? ???? ??...   \n",
       "..                                                 ...   \n",
       "416  jennifer d. paã±o, jeralden r. jumao-as, march...   \n",
       "417            randy e. pederi mary gretchen f. chaves   \n",
       "418  teovy erdel bongcales, ariel balunan, loriemar...   \n",
       "419  steven elizalde, romeo patan mary gretchen chaves   \n",
       "420  albie mae g. sumaylo, christine mae s. babon, ...   \n",
       "\n",
       "             partition_name                                             embeds  \n",
       "0    social_posts_partition  [0.018143652006983757, -0.04928550496697426, 0...  \n",
       "1    social_posts_partition  [0.01835092157125473, -0.0741904154419899, 0.0...  \n",
       "2    social_posts_partition  [0.03154794126749039, -0.06222093477845192, 0....  \n",
       "3    social_posts_partition  [0.015062374994158745, -0.07406798750162125, 0...  \n",
       "4    social_posts_partition  [0.034660838544368744, -0.058060452342033386, ...  \n",
       "..                      ...                                                ...  \n",
       "416     documents_partition  [-0.007246498018503189, -0.04587141051888466, ...  \n",
       "417     documents_partition  [-0.004172301385551691, -0.047382697463035583,...  \n",
       "418     documents_partition  [-0.01086932048201561, -0.04749814048409462, 0...  \n",
       "419     documents_partition  [0.00848416518419981, -0.025945544242858887, 0...  \n",
       "420     documents_partition  [-0.001516345189884305, -0.051354434341192245,...  \n",
       "\n",
       "[421 rows x 3 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaf604",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e61d3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Transform the partition names into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(df['partition_name'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['embeds'].tolist(), y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "def rank_partitions(prompt_embedding):\n",
    "\n",
    "    # Predict the class probabilities\n",
    "    probabilities = svm_model.predict_proba([prompt_embedding])\n",
    "    \n",
    "    # Get the classes and their corresponding probabilities\n",
    "    classes_and_probabilities = zip(label_encoder.classes_, probabilities[0])\n",
    "    \n",
    "    # Sort the classes by probability\n",
    "    ranked_classes = sorted(classes_and_probabilities, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract the class names, ignoring the probabilities\n",
    "    ranked_class_names = [item[0] for item in ranked_classes]\n",
    "    \n",
    "    return ranked_class_names\n",
    "\n",
    "# Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c231cb",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b83efd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['documents_partition', 'people_partition', 'social_posts_partition']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompt = \"Jovelyn Cuizon\"\n",
    "result = rank_partitions(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2d94211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model and the label encoder\n",
    "svm_model = load('svm_model.joblib')\n",
    "label_encoder = load('label_encoder.joblib')\n",
    "\n",
    "# Define the function\n",
    "def rank_partitions(prompt_embedding):\n",
    "    # Convert the prompt to an embedding\n",
    "    \n",
    "    # Predict the class probabilities\n",
    "    probabilities = svm_model.predict_proba([prompt_embedding])\n",
    "    \n",
    "    # Get the classes and their corresponding probabilities\n",
    "    classes_and_probabilities = zip(label_encoder.classes_, probabilities[0])\n",
    "    \n",
    "    # Sort the classes by probability\n",
    "    ranked_classes = sorted(classes_and_probabilities, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract the class names, ignoring the probabilities\n",
    "    ranked_class_names = [item[0] for item in ranked_classes]\n",
    "    \n",
    "    return ranked_class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "55c86167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social_posts_partition', 'documents_partition', 'people_partition']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What was announced based on the uniform measurement?\"\n",
    "result = rank_partitions(string_to_embedding(prompt.lower()))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56ad85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
