{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ca7e91",
   "metadata": {},
   "source": [
    "Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f48ed",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, Partition, utility\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692944a9",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479f6aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "crawl-300d-2M-subword/crawl-300d-2M-subword.bin cannot be opened for loading!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1536\u001b[39m,\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfasttext\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m300\u001b[39m}\n\u001b[1;32m      5\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m OPENAI_API_KEY\n\u001b[0;32m----> 6\u001b[0m fasttext_model \u001b[38;5;241m=\u001b[39m \u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrawl-300d-2M-subword/crawl-300d-2M-subword.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/fasttext/FastText.py:441\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m eprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/fasttext/FastText.py:98\u001b[0m, in \u001b[0;36m_FastText.__init__\u001b[0;34m(self, model_path, args)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fasttext\u001b[38;5;241m.\u001b[39mfasttext()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: crawl-300d-2M-subword/crawl-300d-2M-subword.bin cannot be opened for loading!"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "max_tokens = 8000\n",
    "dimensions = {'openai' : 1536,\n",
    "            'fasttext' : 300}\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "fasttext_model = fasttext.load_model('crawl-300d-2M-subword/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ea4e1",
   "metadata": {},
   "source": [
    "Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53d7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change partition_name based on kind of data\n",
    "partition_name = 'rmrj_articles'\n",
    "# Change embedder to either fasttext openai \n",
    "\n",
    "embedder = 'fasttext'\n",
    "dimension = dimensions[embedder]\n",
    "bundled_schema = {'rmrj_articles': ['author', 'title', 'published_date', 'text'],\n",
    "                  'facebook_posts': ['text', 'time', 'link'],\n",
    "                  'usjr_about': ['text', 'content_id'],\n",
    "                  'all': ['author', 'title', 'published_date', 'text', 'time', 'post', 'link', 'content_id']}\n",
    "collection_names = bundled_schema[partition_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bbc1a",
   "metadata": {},
   "source": [
    "Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd5f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, embedding_type):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    model = \"text-embedding-ada-002\"\n",
    "    if embedding_type == 'openai':\n",
    "        return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "    elif embedding_type == 'fasttext':\n",
    "        return fasttext_model.get_sentence_vector(text)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding_type. Expected 'openai' or 'fasttext'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f09ad",
   "metadata": {},
   "source": [
    "Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2771a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the connection already exists\n",
    "if connections.has_connection('default'):\n",
    "    connections.remove_connection('default')  # Disconnect if it exists\n",
    "\n",
    "# Now, reconnect with your new configuration\n",
    "connections.connect(alias='default', host='localhost', port='19530')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b6c72",
   "metadata": {},
   "source": [
    "Input and vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119707da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-VyfbZ***************************************dpzp. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m current_datetime \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me anything about dost and usjr?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m query_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m query_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(query_vectors)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_vectors\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text, model\u001b[38;5;241m=\u001b[39membedding_model):\n\u001b[1;32m      2\u001b[0m    text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-VyfbZ***************************************dpzp. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Convert the datetime object to a string\n",
    "current_datetime = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "question = f\"Tell me anything about dost and usjr?\"\n",
    "query_vectors = get_embedding(question)\n",
    "query_vectors = np.array(query_vectors)\n",
    "if len(query_vectors.shape) == 1:\n",
    "    query_vectors = query_vectors.reshape(1, -1)\n",
    "\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\",  # Distance metric, can be L2, IP (Inner Product), etc.\n",
    "    \"offset\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea22d82",
   "metadata": {},
   "source": [
    "Searching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280046b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name in collection_names:\n",
    "    collection = Collection(f\"{name}_collection\")\n",
    "    collection.load()\n",
    "    result = collection.search(\n",
    "        data=query_vectors,\n",
    "        anns_field=\"embeds\",\n",
    "        param=search_params,\n",
    "        limit=5,\n",
    "        partition_names=[partition_name],\n",
    "        output_fields=[name, 'uuid'],\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a52c87",
   "metadata": {},
   "source": [
    "Results sorting by distance and removal of duplicates (smaller distance is kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c978f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m unique_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(collection_names):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m[i]:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m      7\u001b[0m             uuid \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mentity\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold unique results\n",
    "unique_results = {}\n",
    "\n",
    "for i, name in enumerate(collection_names):\n",
    "    for result in results[i]:\n",
    "        for item in result:\n",
    "            uuid = item.entity.get('uuid')\n",
    "            data = {\n",
    "                'uuid': uuid,\n",
    "                name: item.entity.get(name),\n",
    "                'distance': item.distance\n",
    "            }\n",
    "            \n",
    "            # If this UUID is not in the dictionary, or it is but the new distance is smaller, update the entry\n",
    "            if uuid not in unique_results or item.distance < unique_results[uuid]['distance']:\n",
    "                unique_results[uuid] = data\n",
    "\n",
    "# Convert the dictionary back into a list of dictionaries\n",
    "results_object = list(unique_results.values())\n",
    "\n",
    "# Sort the results by distance\n",
    "sorted_results = sorted(results_object, key=lambda x: x['distance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1ab4b",
   "metadata": {},
   "source": [
    "Top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9221a0a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_results \u001b[38;5;241m=\u001b[39m \u001b[43msorted_results\u001b[49m[:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_results' is not defined"
     ]
    }
   ],
   "source": [
    "final_results = sorted_results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cf3dc",
   "metadata": {},
   "source": [
    "Field completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40485630",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfinal_results\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m collection_names:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_results' is not defined"
     ]
    }
   ],
   "source": [
    "for result in final_results:\n",
    "    for name in collection_names:\n",
    "        if name not in result:\n",
    "            collection = Collection(f\"{name}_collection\")\n",
    "            query = f'uuid == \"{result[\"uuid\"]}\"'\n",
    "            query_result = collection.query(\n",
    "                expr=query, \n",
    "                offset=0, \n",
    "                limit=1, \n",
    "                partition_names=[partition_name], \n",
    "                output_fields=[name], \n",
    "                consistency_level=\"Strong\"\n",
    "            )\n",
    "            if query_result:\n",
    "                result[name] = query_result[0][name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5221ee0",
   "metadata": {},
   "source": [
    "Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813fa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, result in enumerate(final_results):\n",
    "    print(f\"Result {i}: \", result,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_json = json.dumps(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea1f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed17c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "# openai.api_key = 'your-api-key'\n",
    "\n",
    "def generate_response(prompt, database_json):\n",
    "    # Format the input as per the desired conversation format\n",
    "    string_json = json.dumps(database_json)\n",
    "    conversation = [\n",
    "        {'role': 'system', 'content': \"\"\"You are Josenian Quiri. University of San Jose- Recoletos' general knowledge base assistant. Refer to yourself as JQ.\"\"\"},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "        {'role': 'system', 'content': f'Here is the database JSON from your knowledge base: \\n{string_json}'},\n",
    "        {'role': 'user', 'content': ''}\n",
    "    ]\n",
    "    \n",
    "    # Convert the conversation to a string\n",
    "    conversation_str = ''.join([f'{item[\"role\"]}: {item[\"content\"]}\\n' for item in conversation])\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=conversation,\n",
    "      temperature=1,\n",
    "      max_tokens=500,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    # Extract the generated response from the API's response\n",
    "    generated_text = response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "    # Return the response\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "prompt = question\n",
    "\n",
    "response = generate_response(prompt, final_results)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e152f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01e9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5068bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eb8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec8385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
